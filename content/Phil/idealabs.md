---
title: "Idea Labs"
slug: "Idea Labs"

---

# Idea Labs

This page is heavily inspired by [Idea Labs and Echo Chambers](https://waitbutwhy.com/2019/10/idea-labs-echo-chambers.html), which is Part 8 of [The Story Of Us](https://waitbutwhy.com/2019/08/story-of-us.html). It's a long read, but worth the time. Rather than try to repeat here what is put so well there, I'm going to recommend you read at least that section and come back here.

Read it? Cool.

The big take away is free speech & spread of ideas = good, echo chambers = bad. And, like, yeah? That's pretty hard to disagree with. However, it reminds me of the often repeated line "There's no such thing as a stupid idea!" and that quote really, really drives me nuts.

Unfortunately, some ideas, even when we can make well thought out arguments for why the idea itself is absolute bunk and the supposed evidence for their idea is also bunk, still persist. Obviously, this is on a spectrum: Flat Earthers? Idiots. Those that think there has been extraterrestrial life on earth before? Maybe worth listening to. Those that think aliens built the pyramids and that someday they'll send beams of light into the sky to call down our gray skinned, big headed overlords to provide us with infinite energy, end hunger, and cure cancer? Back to idiots. Extraordinary claims require extraordinary evidence and all that jazz.    

So why does it matter if someone has a stupid idea:

1. Stupid ideas keep us from the truth- if a huge number of people believe the earth is flat, that's a huge number of people that think something that is demonstrably false
2. Stupid ideas can hurt people - Anti-vax, racism, sexism, etc.

So, what should we do?

Generally, I've seen two ways to go about dealing with stupid ideas:

1. Debate them, make them look dumb
2. De-platfrom them, don't let the idea spread

Both have the same issue though: they spread the idea further

1. Debating them **gives them a platform** and by acknowledging their idea, makes it look like a legitimate option with the same standing as the idea that's not a load of shit. Think climate change, flat-earth, or creationism debates. It also exposes the idea to more people.
2. De-platforming makes the echo chamber even stronger as the people with the idea will form their own communities instead of talking in the public where they can be called out. Plus, it often makes these people feel *more confident* in their ideas because "The public is scared of the truth!" or something alone those lines. Deplatforming may make the idea less discoverable; however, it does make it much easier for someone on the tipping point of falling in to get sucked in and stay there.

So, which is the right answer?

This is philosophy. There is no right answer. Ideally, we'd actually be able to convince the idiots to stop being idiots, but historically that doesn't really work. Deplatforming can work, but it can lead to extremism on both sides, and can be abused. It's a bit of a nuclear option, and if we use it wrong, it can hurt people. As much as I, personally, am for deplatforming anti-vax talk show hosts, I've also seen the havoc caused by "the other side" getting payment processors and big websites to stop supporting sexual content, hurting sex workers.

There's a lot of debate around this too, [Mozilla published "We Need More than Deplatforming"](https://blog.mozilla.org/en/mozilla/we-need-more-than-deplatforming/) which received [heavy criticism on Hacker News](https://news.ycombinator.com/item?id=25690941). Meanwhile, [A Heretics Guide to Deplatforming](https://easydns.com/blog/2018/11/02/a-heretics-guide-to-deplatforming/) resulted in [mixed, but some pro-moderation comments on Hacker News](https://news.ycombinator.com/item?id=18365851). Ultimately, it boils down to two age-old questions about free speech: 

1. Should speech that harms others be "free"?
2. Should a given venue/platform be required to let you say whatever you want there?

The answer to 2. seems to be of more importance again, now, in the internet era. Strangely, It seems this has largely been decided for physical spaces, where if I walk into a business and start going on about how "all these damn ░░░░░ keep making ░░░░░ worse for us and they should go back where they came from!" I'm going to get kicked out, and everyone is fine with that. Meanwhile, if Facebook or Twitter kick me out, some people will argue I have a *right* to be there. Personally, I think this is a load of shit. If you want to post your hate, go post it on your own site. Nobody is obligated to give you the platform on which to preach your shit from. I think the larger argument comes when lower-level infrastructure providers choose weather or not you can use their services for given speech. Should Amazon have the right to say "If you post hate speech we won't let you host your website on AWS?" (Amazon Web Services is a common server platform on which you could put your own, custom made website). On one hand, Amazon is a private business and should be able to refuse service, on the other hand, there's a limited number of hosting providers that could allow you to deploy a large website with lots of traffic. Is this the same as limiting more traditional infrastructure, like roads, to only those we think deserve a voice?

As for 1. - IMHO, yeah, free speech should probably be free *from government retaliation*, even if it's hate speech. Otherwise, there's a huge risk of abuse and the loss of the free exchange of good ideas. This is my opinion though, and this opinion is deserving of a page in this chapter of OpGuides all its own. Suffice to say, there are good arguments on both sides. Obviously, some limits should apply no matter what- the "don't yell fire in a crowded theater" rules still apply. 

All of that said, to some extent, **deplatforming is necessary** because a lot of people with shit ideas know how to spread them in a way that prevents even logical debate from refuting it. Largely, this is done by using one of a handful of tactics:

1. By spewing shit faster than the opponent can respond with corrections for - that is [Never play defense (YouTube, The Alt-Right Playbook by Innuendo Studios)](https://www.youtube.com/watch?v=wmVkJvieaOA)
2. By moving the goalpost **or** change the topic subtly - that is [Control the conversation (YouTube, The Alt-Right Playbook by Innuendo Studios)](https://www.youtube.com/watch?v=CaPgDQkmqqM)
3. By talking about their points publicly, they manage to go [Mainstream (YouTube, The Alt-Right Playbook by Innuendo Studios)](https://www.youtube.com/watch?v=Gq0ZHgKT2tc)
4. By stretching the meaning of something, in a way that's not *technically* false - see [The Ship of Theseus (YouTube, The Alt-Right Playbook by Innuendo Studios)](https://www.youtube.com/watch?v=Ui-ArJRqEvU)

The **only way** to stop this is to *not debate them* and to *remove their platform*. If you play fair and want to actually question ideas, you're good. If you're here to spread hate, hurt people, and (intentionally or not) use tactics that prevent real debate, you should lose your platform. I think, as a society, we're pretty good at knowing where this line is. The issue of false-positives is real and platforms still need to be careful to avoid over moderation and turning into echo chambers or not allowing honestly, good faith criticism. Still, most platform are actually on the opposite side of this: Twitter for example is still full of people saying extreme threats towards trans people. 

---

Not to miss the forest for the tress, it's worth pointing out that, largely, competing ideas and seeing things differently is a driving force of knowledge and understanding. Limiting our intake to only views we agree with, weather we're aware of it or not, is bad. It's the reason why headlines like [These 6 corporations control 90% of the media outlets in America. (TechStartups)](https://techstartups.com/2020/09/18/6-corporations-control-90-media-america-illusion-choice-objectivity-2020/) and [Last Week Tonight's piece on Sinclair Broadcast Group](https://www.youtube.com/watch?v=GvtNyOzGogc) are so terrifying: We don't want all of our information to be filtered and have opinions baked in. The problem is we now have multiple, conflicting goals:

1. Facilitate the spread of as many good, novel ideas as possible
2. Prevent the spread of *diseased* ideas- ideas that can pass for being good, can spread quickly, but are actually shit.
3. Never accidentally mark a good idea as diseased or a diseased idea as good

So, how do we do this?

Let's look at each piece

## 1. Facilitate Novel, Good Ideas

So, while we want to avoid bad ideas, we still want to generate as many novel, good ideas as we can. It's easy to be negative and list the things that prevent this from happening (gatekeeping, lack of access to resources, etc) but I think this page needs some positivity, so what can be done to make things easier?

### Host or join an open, organized, small, active community

> Note, you'll probably want to be in multiple groups, each related to a topic you're interested in. It's often best to be in both a general and specific chat. For example, if you're into guitar, join/host a community focused on music and a community focused on guitar.

**Open** - All are welcome until they show a reason not to be

**Organized** - Chat is kept reasonably on topic, tangents welcome, but only for limited periods of time. If there's sub-topics, each topic has its own space.

**Small** - Communities over about 30 active members tend to become unpersonal. You should maintain smaller pods like this to keep things actually flowing. This does mean some segregation in the community, but it also keeps the chat feeling like a chat and not a place just for showcases or tough questions.

**Active** - Active means more than just ongoing participation. It means events, competitions, chances to demonstarte knowledge and challage one another. Give people a time to look forward to and plan to interact in advance. Services like https://www.gather.town, https://www.calla.chat, or even using [Spacial Audio With Minecraft](https://www.highfidelity.com/blog/how-to-create-a-minecraft-mod-with-spatial-audio-voice-chat)

### Host or join a community knowledge garden

A community is great, but having a community repository of ideas and knowledeg is even better. Everyone brings a different background, and with enough contributors a lot can happen. Small contributions, every day, over the course of a long time can make something much bigger than you may initally think possible.

While I love OpGuides, even I acknowledge the way it is setup makes contribution less than seamless. If you're going to setup a knowledge garden of your own, make sure it's setup in a way that everyone in the community finds accessible. If everyone knows how to use git, then maybe something like a fork of this site is a good start, otherwise, something like [Wiki.js](https://js.wiki) may work better.

If you can, find a way to incentivize contribution to the garden

### Keep a *Personal* knowledge garden too

As much as it's nice to have all the community pages to fall back on, having a hand pruned, personal database of links and information is immensely helpful. If you keep it private, you can associate it with your TODOs and a daily journal as well

### Seek experiences outside your comfort zone



### Relate experiences across disciplines 



### Try things you expect to fail at, and welcome the failures

[TODO] ThoughtEmporium YT Channel doing crazy things that *feel* to complicated

### Realize the sources available to you

[TODO] Scihub, emailing the original researchers, etc - no harm in asking, see interviews on this page



[TODO] in the previous chapter hackerspaces, open source, etc.

<iframe width="100%" height="500" src="https://www.youtube.com/embed/vKA4w2O61Xo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## 2. Prevent Diseased Ideas From Spreading

Calling an idea 'Diseased' may sound a bit like it's a term from the Thought Police from Orwell's *1984*. Yet, I think it's a fair term as some ideas start out incorrect, yet more or less benign, but then pick up more and more malicious elements and hooks into our psyche that act as diseases that hard to shake and often chronic. They bury into our brains using tricks not of the thinking mind, but of faith or prejudice or instinct. They reaffirm what we *want* to believe or they allow us to ignore truths, often about ourselves, that we'd rather not think of. Some of these ideas, other than being false, are more or less harmless. Others, especially when used to foster action, can lead to bloodshed. There is, of course, the risk for a good idea to be labeled diseased. Maybe a culture of homophobia has become so prevalent that even thinking gay people deserve to marry is seen as a disease of the mind. This is obviously awful, yet if we let simple majority pick what ideas are okay, it is also inevitable. So when I called an idea *diseased* I mean that it has all of these qualities:

1. **It is false.** Not just the majority of people think it is false, but that by some *ground truth* it can be shown to be false. This is difficult when talking abortion access or homophobia, but even in those cases there is data that can be used to show the argument- such as the [rate of violent crime done to LGBT people](https://williamsinstitute.law.ucla.edu/press/ncvs-lgbt-violence-press-release/) or [Abortion rates being highest where legally restricted](https://www.scidev.net/global/news/abortion-rates-highest-where-legally-restricted-study/). It may even be that the majority of people think a diseased idea is true, that just makes it an epidemic.
2. **It has emotional backing** - almost all ideas that are harmful but spread quickly have an emotional basis- be it abortion, homophobia, religious persecution, racism, etc.
3. **It has good looking bullshit to back it up** - At some point someone, somewhere has put in effort to make a very convincing argument using bullshit in one way or another. Maybe P-hacking, maybe publishing in a journal that sounds good but has poor standards, maybe just getting on prime-time television with a celebrity endorsement. What matters is that this idea has something that is giving it undeserved legitimacy.  

### P-hacking, Fake Science, and Academia's Bullshit

{{< columns3 >}}

{{< best >}} [Scientific Studies (Last Week Tonight, YouTube)](https://www.youtube.com/watch?v=0Rnq1NpHdmw) {{< /best >}}

<--->

[Academic journal publishing reform (Wikipedia)](https://en.wikipedia.org/wiki/Academic_journal_publishing_reform)

[List of scholarly publishing stings (Wikipedia)](https://en.wikipedia.org/wiki/List_of_scholarly_publishing_stings)

[Predatory Publishing (Wikipedia)](https://en.wikipedia.org/wiki/Predatory_publishing)

{{< /columns3 >}}

</br>

<iframe width="100%" height="500" src="https://www.youtube.com/embed/ras_VYgA77Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

{{< columns >}}

<iframe width="100%" height="200" src="https://www.youtube.com/embed/Gx0fAjNHb1M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<--->

<iframe width="100%" height="200" src="https://www.youtube.com/embed/42QuXLucH3Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

{{< /columns >}}

Academia and the publishing houses have also made extreme efforts to keep science, even that which is publicly funded, behind paywalls. Fortunately, efforts like SciHub, ArXiv, and LibGen have dramatically increased access to the output of academia for the public, though the fight is still ongoing. I really recommend watching this documentary on the story of Aaron Swartz, a young man that tried to fight this system at the cost of his life.

<iframe width="100%" height="500" src="https://www.youtube.com/embed/9vz06QO3UkQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

I'd also like to touch on paid-for research. It's easy to think this is a problem of the past, that it was a problem back when cigarette companies bouught research to hide that they caused cancer- but guess what! That's still a problem: [Juul: Taking Academic Corruption to a New Level (The American Post)](https://prospect.org/health/juul-taking-academic-corruption-to-new-level/)

## 3. Never Mark A Good Idea as Diseased or A Diseased Idea as Good

Until about the 17th century most people believed the Earth was the center of the universe, and that all celestial bodies rotated around it. This, on it's own, is *not* a bad idea. It was an attempt to explain a natural process. The problem turned out to be the over confidence in this assumption, and the refusal of evidence contrary - especially by the church which held great power at the time. The problem for us, today, is to have the foresight to recognize when we may be making the same mistakes and catch them early, while still not allowing stupid shit to get though. This creates a natural tension. For example, vaccines & cigarettes:

Should we look into the safety of Vaccines? Of course! But it only takes a little fear mongering and one [crazy ex-physician](https://en.wikipedia.org/wiki/Andrew_Wakefield) with a known [conflict of interest](https://en.wikipedia.org/wiki/Lancet_MMR_autism_fraud#Conflict_of_interest) writing a paper linking vaccines to autism to result in countless extra deaths. 

Should we look into the safety of cigarettes? Yeah, no shit. However, our over hesitancy to declare them cancerous doubtlessly lead to tons more cancer world wide. Why? Because of ton of academic papers, funded by the cigarette companies, that basically boiled down to "Yeah, people are getting cancer more, but maybe that's plastic use, or this, or that - you don't *know* that it's cigarettes causing it", and then, when the link became undeniable, they just spun it as "Of course, we've always told you it can cause cancer, but you knew that going in!"

{{< attribution >}}Of note, I could also really say Nazis fall into this boat too, as a failing to identify their ideas as evil and convince enough people of that to stop it lead to WWⅡ; however, I think that is to reductive of history and of the efforts of people who did actually try to stop it from the start. Also I don't want to add fuel to the fire of [Godwin's Law](https://en.wikipedia.org/wiki/Godwin's_law){{< /attribution >}}

In both of these, the cost of failing to declare the studies as bullshit from the start resulted in deaths. While one was an over-abundance of caution, the other was a lack of. Both should be appreciated as equally dangerous.

Meanwhile, failing to let new ideas surface because they sound crazy can cause similar issues. Unfortunately, these examples are a lot harder to identify. There's the obvious poster child examples, like the light bulb that supposedly got  significant push back for never having the possibility of being commercially viable, or Airplanes and the story of the Wright Brothers. The real question is what inventions did we lose or get a hundred years late because the ideas were ridiculed?

We can never fully making mistakes. Some bad ideas will get though, and propagate enough to become diseased. Some good ideas will be squashed early. We should try our best though. This means encouraging people with new ideas to test them out while also helping people recognize what may make an idea dangerous - while avoiding falling into patterns that lead to not questioning our own beliefs and without going off the deep end and questioning everything that keeps society moving.

Balance skepticism with openness.
