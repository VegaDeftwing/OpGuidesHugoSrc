---
title: "Idea Labs"
slug: "Idea Labs"

---

# Idea Labs

This page is heavily inspired by [Idea Labs and Echo Chambers](https://waitbutwhy.com/2019/10/idea-labs-echo-chambers.html), which is Part 8 of [The Story Of Us](https://waitbutwhy.com/2019/08/story-of-us.html). It's a long read, but worth the time- you could read just the one part; however, I think it will be harder to understand without the previous 7 parts as context. Rather than try to repeat here what is put so well there, I'm going to recommend you read at least that section and come back here.

Read it? Cool.

The big take away is free speech & spread of ideas = good, echo chambers = bad. And, like, yeah? That's pretty hard to disagree with. However, it reminds me of the often repeated line "There's no such thing as a stupid idea!" and that quote really, really drives me nuts.

Unfortunately, some ideas, even when we can make well thought out arguments for why the idea itself is absolute bunk and the supposed evidence for their idea is also bunk, still persist. Obviously, this is on a spectrum: Flat Earthers? Idiots. Those that think there has been extraterrestrial life on earth before? Maybe worth listening to. Those that think aliens built the pyramids and that someday they'll send beams of light into the sky to call down our gray skinned, big headed overlords to provide us with infinite energy, end hunger, and cure cancer? Back to idiots. Extraordinary claims require extraordinary evidence and all that jazz.    

So why does it matter if someone has a stupid idea:

1. Stupid ideas keep us from the truth- if a huge number of people believe the earth is flat, that's a huge number of people that think something that is demonstrably false
2. Stupid ideas can hurt people - Anti-vax, racism, sexism, etc.

So, what should we do?

Generally, I've seen two ways to go about dealing with stupid ideas:

1. Debate them, make them look dumb
2. De-platfrom them, don't let the idea spread

Both have the same issue though: they spread the idea further

1. Debating them **gives them a platform** and by acknowledging their idea, makes it look like a legitimate option with the same standing as the idea that's not a load of shit. Think climate change, flat-earth, or creationism debates. It also exposes the idea to more people.
2. De-platforming makes the echo chamber even stronger as the people with the idea will form their own communities instead of talking in the public where they can be called out. Plus, it often makes these people feel *more confident* in their ideas because "The public is scared of the truth!" or something alone those lines. Deplatforming may make the idea less discoverable; however, it does make it much easier for someone on the tipping point of falling in to get sucked in and stay there.

So, which is the right answer?

This is philosophy. There is no right answer. Ideally, we'd actually be able to convince the idiots to stop being idiots, but historically that doesn't really work. Deplatforming can work, but it can lead to extremism on both sides, and can be abused. It's a bit of a nuclear option, and if we use it wrong, it can hurt people. As much as I, personally, am for deplatforming anti-vax talk show hosts, I've also seen the havoc caused by "the other side" getting payment processors and big websites to stop supporting sexual content, hurting sex workers.

There's a lot of debate around this too, [Mozilla published "We Need More than Deplatforming"](https://blog.mozilla.org/en/mozilla/we-need-more-than-deplatforming/) which received [heavy criticism on Hacker News](https://news.ycombinator.com/item?id=25690941). Meanwhile, [A Heretics Guide to Deplatforming](https://easydns.com/blog/2018/11/02/a-heretics-guide-to-deplatforming/) resulted in [mixed, but some pro-moderation comments on Hacker News](https://news.ycombinator.com/item?id=18365851). Ultimately, it boils down to two age-old questions about free speech: 

1. Should speech that harms others be "free"?
2. Should a given venue/platform be required to let you say whatever you want there?

The answer to 2. seems to be of more importance again, now, in the internet era. Strangely, It seems this has largely been decided for physical spaces, where if I walk into a business and start going on about how "all these damn ░░░░░ keep making ░░░░░ worse for us and they should go back where they came from!" I'm going to get kicked out, and everyone is fine with that. Meanwhile, if Facebook or Twitter kick me out, some people will argue I have a *right* to be there. Personally, I think this is a load of shit. If you want to post your hate, go post it on your own site. Nobody is obligated to give you the platform on which to preach your shit from. I think the larger argument comes when lower-level infrastructure providers choose whether or not you can use their services for given speech. Should Amazon have the right to say "If you post hate speech we won't let you host your website on AWS?" (Amazon Web Services is a common server platform on which you could put your own, custom made website). On one hand, Amazon is a private business and should be able to refuse service, on the other hand, there's a limited number of hosting providers that could allow you to deploy a large website with lots of traffic. Is this the same as limiting more traditional infrastructure, like roads, to only those we think deserve a voice?

As for 1. - IMHO, yeah, free speech should probably be free *from government retaliation*, even if it's hate speech. Otherwise, there's a huge risk of abuse and the loss of the free exchange of good ideas. This is my opinion though, and this opinion is deserving of a page in this chapter of OpGuides all its own. Suffice to say, there are good arguments on both sides. Obviously, some limits should apply no matter what- the "don't yell fire in a crowded theater" rules still apply. 

All of that said, to some extent, **deplatforming is necessary** because a lot of people with shit ideas know how to spread them in a way that prevents even logical debate from refuting it. Largely, this is done by using one of a handful of tactics:

1. By spewing shit faster than the opponent can respond with corrections for - that is [Never play defense (YouTube, The Alt-Right Playbook by Innuendo Studios)](https://www.youtube.com/watch?v=wmVkJvieaOA)
2. By moving the goalpost **or** change the topic subtly - that is [Control the conversation (YouTube, The Alt-Right Playbook by Innuendo Studios)](https://www.youtube.com/watch?v=CaPgDQkmqqM)
3. By talking about their points publicly, they manage to go [Mainstream (YouTube, The Alt-Right Playbook by Innuendo Studios)](https://www.youtube.com/watch?v=Gq0ZHgKT2tc)
4. By stretching the meaning of something, in a way that's not *technically* false - see [The Ship of Theseus (YouTube, The Alt-Right Playbook by Innuendo Studios)](https://www.youtube.com/watch?v=Ui-ArJRqEvU)

The **only way** to stop this is to *not debate them* and to *remove their platform*. If you play fair and want to actually question ideas, you're good. If you're here to spread hate, hurt people, and (intentionally or not) use tactics that prevent real debate, you should lose your platform. I think, as a society, we're pretty good at knowing where this line is. The issue of false-positives is real and platforms still need to be careful to avoid over moderation and turning into echo chambers or not allowing honestly, good faith criticism. Still, most platform are actually on the opposite side of this: Twitter for example is still full of people saying extreme threats towards trans people. 

---

Not to miss the forest for the tress, it's worth pointing out that, largely, competing ideas and seeing things differently is a driving force of knowledge and understanding. Limiting our intake to only views we agree with, whether we're aware of it or not, is bad. It's the reason why headlines like [These 6 corporations control 90% of the media outlets in America. (TechStartups)](https://techstartups.com/2020/09/18/6-corporations-control-90-media-america-illusion-choice-objectivity-2020/) and [Last Week Tonight's piece on Sinclair Broadcast Group](https://www.youtube.com/watch?v=GvtNyOzGogc) are so terrifying: We don't want all of our information to be filtered and have opinions baked in. The problem is we now have multiple, conflicting goals:

1. Facilitate the spread of as many good, novel ideas as possible
2. Prevent the spread of *diseased* ideas- ideas that can pass for being good, can spread quickly, but are actually shit.
3. Never accidentally mark a good idea as diseased or a diseased idea as good

So, how do we do this?

Let's look at each piece

## 1. Facilitate Novel, Good Ideas

So, while we want to avoid bad ideas, we still want to generate as many novel, good ideas as we can. It's easy to be negative and list the things that prevent this from happening (gatekeeping, lack of access to resources, etc) but I think this page needs some positivity, so what can be done to make things easier?

### Host or join an open, organized, small, active community

> Note, you'll probably want to be in multiple groups, each related to a topic you're interested in. It's often best to be in both a general and specific chat. For example, if you're into guitar, join/host a community focused on music and a community focused on guitar.

**Open** - All are welcome until they show a reason not to be

**Organized** - Chat is kept reasonably on topic, tangents welcome, but only for limited periods of time. If there's sub-topics, each topic has its own space.

**Small** - Communities over about 30 active members tend to become unpersonal. You should maintain smaller pods like this to keep things actually flowing. This does mean some segregation in the community, but it also keeps the chat feeling like a chat and not a place just for showcases or tough questions.

**Active** - Active means more than just ongoing participation. It means events, competitions, chances to demonstarte knowledge and challage one another. Give people a time to look forward to and plan to interact in advance. Services like https://www.gather.town, https://www.calla.chat, or even using [Spacial Audio With Minecraft](https://www.highfidelity.com/blog/how-to-create-a-minecraft-mod-with-spatial-audio-voice-chat)

If you're lucky, there may be a [hackerspace near you](https://wiki.hackerspaces.org/List_of_Hacker_Spaces), it's worth checking at least ↓

<iframe width="100%" height="500" src="https://www.youtube.com/embed/nsiYTBQpIJ8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

I'll touch more on community resources and what a healthy community looks like in the next page, <a href="/phil/community/">Community Efforts</a>

### Host or join a community knowledge garden

{{< columns >}}

<img src="/phil/groupwork.svg" alt="Group Work">

<--->

A community is great, but having a community repository of ideas and knowledge is even better. Everyone brings a different background, and with enough contributors a lot can happen. Small contributions, every day, over the course of a long time can make something much bigger than you may initially think possible.

While I love OpGuides, even I acknowledge the way it is setup makes contribution less than seamless. If you're going to setup a knowledge garden of your own, make sure it's setup in a way that everyone in the community finds accessible. If everyone knows how to use git, then maybe something like a fork of this site is a good start, otherwise, something like [Wiki.js](https://js.wiki) may work better.

If you can, find a way to incentivize contribution to the garden

{{< /columns >}}

### Keep a *Personal* knowledge garden too

As much as it's nice to have all the community pages to fall back on, having a hand pruned, personal database of links and information is immensely helpful. If you keep it private, you can associate it with your TODOs and a daily journal as well. Tools like https://obsidian.md and https://github.com/zadam/trilium work well for this

### Seek experiences outside your comfort zone, <BR>Encourage Others to do so too

{{< columns >}}

<img src="/phil/sarahcomfortzone.webp">

{{< attribution >}}Comic by [Sarah Scribbles](https://sarahcandersen.com/about){{< /attribution >}}

<--->

One of the biggest ways to *stop* gaining knowledge is to just keep doing the same thing over and over again or only tacking projects that you know you have the skills to do. It's only when pushed with new challenges that people really learn. **Try things you expect to fail at and welcome the failures**. Everyone sucks at everything the first time they try it.

For me, my biggest inspiration is seeing people like [The Thought Emporium](https://www.youtube.com/c/thethoughtemporium) work on projects that just *sound* like they should only be possible when tackled by huge teams of people - like genetic engineering and detecting antimater - and turning them into projects that take a few weeks (albeit they still require some pricey equipment)

Be sure to document your failures too, both in your personal and community knowledge gardens if you can. Science is largely focused on the successes, but sometimes sharing failures so that you can remind your future self and warn others about the wrong steps is worth more than a success.

To some extent, all of this requires a few things that a lot of people think that they lack: Confidence and Dedication. Fortunately, both of those are things that being part of a larger community and keeping a log of your past experience will help with. 

{{< /columns >}}

### Relate experiences across disciplines 

Pick any two interests and mix em' together. Into music and electronics? Build a synth. Into drones and art? Make a light show. Into speed running videos games and writing comics? Write a comic about the struggles of a speed runner. These intersections of interests are where magic happens.

### Realize the sources available to you

Sometimes, it's easy to think "I just need to take a class on this" or "I can't afford the tutor" etc. But, come on. There is free information on literally every topic you could ever want to look into. With websites like SciHub, ArXiv, and LibGen you can find any academic source you'd want. Plus, YouTube has amazing presentations from experts about an ever growing list of increasingly specific topics. Even better if you ever want to talk to an expert, most would *love* to talk to you too - just send them an email. All of this is entirely free, it doesn't cost you a dime.

See all those interviews on this page? The first one I published was with an engineer that worked on high speed cameras then next up was a big name security researcher - all I did was shoot them a message and say "Hey, are you interested in doing an interview for my website?". If all you want is to talk about what that person is passionate about, most will be more than willing to hang out for a bit. Yeah, sometimes you'll send an email and never get a response but more often than not you'll get the chance to chat one-on-one with someone that has a wealth of knowledge to share. Hell, you may even accidentally end up teaching them something, especially if you're applying their knowledge in a novel way.

If you're willing to share what you make too, the open source community is full of amazing software and hardware projects, often with great documentation.

### Be aware of your own biases

{{< columns >}}

<img src="/phil/propaganda.webp">

<--->

When most people think biases, they think 'racist' or 'wealthy' or something societal, but [Cognitive Biases (Wikipedia)](https://en.wikipedia.org/wiki/List_of_cognitive_biases) are just as important to recognize. Some of these biases are just human nature, some are the result of seeing repeated ads or hearing the same quotes over and over again, without really thinking about the implications of them.

I highly recommend going though the list on that linked Wikipedia page, but there's a few major ones I'd like to point out that are not covered on the <a href="/phil/fallacies/">Logical Fallacies+</a> page:

{{< /columns >}}

{{< quote "[Wikipedia](https://en.wikipedia.org/wiki/List_of_cognitive_biases)" >}}

| Bias                                                         | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [Curse of knowledge](https://en.wikipedia.org/wiki/Curse_of_knowledge) | When better-informed people find it extremely difficult to think about problems from the perspective of lesser-informed people. |
| [Law of the instrument](https://en.wikipedia.org/wiki/Law_of_the_instrument) | An over-reliance on a familiar tool or methods, ignoring or under-valuing alternative approaches. "If all you have is a hammer, everything looks like a nail." |
| [Framing effect](https://en.wikipedia.org/wiki/Framing_effect_(psychology)) | Drawing different conclusions from the same information, depending on how that information is presented. |
| [Disposition effect](https://en.wikipedia.org/wiki/Disposition_effect) | The tendency to sell an asset that has accumulated in value and resist selling an asset that has declined in value. |
| [Loss aversion](https://en.wikipedia.org/wiki/Loss_aversion) | The perceived disutility of giving up an object is greater than the utility associated with acquiring it. |
| [Illusory truth effect](https://en.wikipedia.org/wiki/Illusory_truth_effect) | A tendency to believe that a statement is true if it is easier to process, or if it has been stated multiple times, regardless of its actual veracity. |
| [Not invented here](https://en.wikipedia.org/wiki/Not_invented_here) | Aversion to contact with or use of products, research, standards, or knowledge developed outside a group. |

{{< /quote >}}

<iframe width="100%" height="500" src="https://www.youtube.com/embed/vKA4w2O61Xo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## 2. Prevent Diseased Ideas From Spreading

Calling an idea 'Diseased' may sound a bit like it's a term from the Thought Police from Orwell's *1984*. Yet, I think it's a fair term. Some ideas start out incorrect, yet more or less benign, but then pick up more and more malicious elements and hooks into our psyche until they act as diseases that is hard to shake and often chronic. They bury into our brains using tricks not of the thinking mind, but of faith or prejudice or instinct. They reaffirm what we *want* to believe or they allow us to ignore truths, often about ourselves, that we'd rather not think of.

Some of these ideas, other than being false, are more or less harmless. Others, especially when used to foster action, can lead to bloodshed. There is, of course, the risk for a good idea to be labeled diseased. Maybe a culture of homophobia has become so prevalent that even thinking gay people deserve to marry is seen as a disease of the mind. This is obviously awful, yet if we let simple majority pick what ideas are okay, it is also inevitable. So when I called an idea *diseased* I mean that it has all of these qualities:

1. **It is false.** Not just the majority of people think it is false, but that by some *ground truth* it can be shown to be false. This is difficult when talking abortion access or homophobia, but even in those cases there is data that can be used to show the argument- such as the [rate of violent crime done to LGBT people](https://williamsinstitute.law.ucla.edu/press/ncvs-lgbt-violence-press-release/) or [Abortion rates being highest where legally restricted](https://www.scidev.net/global/news/abortion-rates-highest-where-legally-restricted-study/). It may even be that the majority of people think a diseased idea is true, that just makes it an epidemic.
2. **It has emotional backing** - almost all ideas that are harmful but spread quickly have an emotional basis- be it abortion, homophobia, religious persecution, racism, etc.
3. **It has good looking bullshit to back it up** - At some point someone, somewhere has put in effort to make a very convincing argument using bullshit in one way or another. Maybe P-hacking, maybe publishing in a journal that sounds good but has poor standards, maybe just getting on prime-time television with a celebrity endorsement. What matters is that this idea has something that is giving it undeserved legitimacy.  

So, how to we stop these ideas from spreading? Our only options are to **help people see the facts though their feelings** or to **remove the good looking bullshit**

### Facts though the feelings

**Facts do care about your feelings**

In a debate, what's important *is not* the facts, but how people remember the interaction. If you're always playing defense, correcting your opponent, you'll look weak. This is how other people will remember the situation- our brains don't remember the good arguments and the minor details, they remember who spoke with conviction and made us feel things. So, how can you present facts and get past people's feelings to actually change their minds?

1. Don't let them control the conversation or make you play defense

   Keep the conversation on topic, even if it means letting misinformation be said. Do not interrupt to correct them.

   Don't let them ask "the next question" as if you've already agreed to a premise

   Keep them spending just as much time answering questions as you are

2. Don't make them feel guilty, but explain how society may have let them learn something wrong

   **DONT:** "Using the term gay as in insult will make LGBT people around you feel uncomfortable"

   **DO:** "You heard 'gay' used as in insult in middle school over and over again- of course you picked up the association that you did - but just because society largely used derogatory words for different races for a long time didn't make that right either"

3. Don't show them the correct information to start, show them how what they think may have been presented with an agenda, may be misleading, or may be from a bad source

   **DONT:** "According to NOAA's 2020 Annual Climate Report the combined land and ocean temperature has increased at an average rate of 0.13 degrees Fahrenheit ( 0.08 degrees Celsius) per decade since 1880; however, the average rate of increase since 1981 (0.18°C / 0.32°F) has been more than twice that rate" ([source](https://www.climate.gov/news-features/understanding-climate/climate-change-global-temperature))

   **DO:** "Every year, the world's five largest publicly owned oil and gas companies spend approximately $200 million on lobbying designed to control, delay or block binding climate-motivated policy" ([source](https://www.forbes.com/sites/niallmccarthy/2019/03/25/oil-and-gas-giants-spend-millions-lobbying-to-block-climate-change-policies-infographic/?sh=2296563f7c4f)). "Polls conducted in May 2020 showed that just 22% of Americans who vote Republican believed climate change is man-made, compared with 72% of Democrats" ([source](https://www.bbc.com/news/stories-53640382)) despite this, 98% of climate researchers agreeing that it is a problem ([source](https://www.pnas.org/content/early/2010/06/04/1003187107)) 

### Good looking Bullshit: P-hacking, Fake Science, and Academia at its worst

For this section, I think the best way to show you the problem is to just let you see it first hand. Here's a bunch of links and videos, I think you'll get the idea if you watch a handful of them.

{{< columns3 >}}

{{< best >}} [Scientific Studies (Last Week Tonight, YouTube)](https://www.youtube.com/watch?v=0Rnq1NpHdmw) {{< /best >}}

[Coronavirus: Conspiracy Theories (Last Week Tonight, YouTube)](https://www.youtube.com/watch?v=0b_eHBZLM6U)

<--->

[Academic journal publishing reform (Wikipedia)](https://en.wikipedia.org/wiki/Academic_journal_publishing_reform)

[List of scholarly publishing stings (Wikipedia)](https://en.wikipedia.org/wiki/List_of_scholarly_publishing_stings)

[Predatory Publishing (Wikipedia)](https://en.wikipedia.org/wiki/Predatory_publishing)

{{< /columns3 >}}

</br>

<iframe width="100%" height="500" src="https://www.youtube.com/embed/ras_VYgA77Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

{{< columns >}}

<iframe width="100%" height="200" src="https://www.youtube.com/embed/Gx0fAjNHb1M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<--->

<iframe width="100%" height="200" src="https://www.youtube.com/embed/42QuXLucH3Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

{{< /columns >}}

Academia and the publishing houses have also made extreme efforts to keep science, even that which is publicly funded, behind paywalls. Fortunately, efforts like SciHub, ArXiv, and LibGen have dramatically increased access to the output of academia for the public, though the fight is still ongoing. I really recommend watching this documentary on the story of Aaron Swartz, a young man that tried to fight this system at the cost of his life.

<iframe width="100%" height="500" src="https://www.youtube.com/embed/9vz06QO3UkQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

I'd also like to touch on paid-for research. It's easy to think this is a problem of the past, that it was a problem back when cigarette companies bouught research to hide that they caused cancer- but guess what! That's still a problem: [Juul: Taking Academic Corruption to a New Level (The American Post)](https://prospect.org/health/juul-taking-academic-corruption-to-new-level/)

## 3. Never Mark A Good Idea as Diseased or A Diseased Idea as Good

Until about the 17th century most people believed the Earth was the center of the universe, and that all celestial bodies rotated around it. This, on it's own, is *not* a bad idea. It was an attempt to explain a natural process. The problem turned out to be the over confidence in this assumption, and the refusal of evidence contrary - especially by the church which held great power at the time. The problem for us, today, is to have the foresight to recognize when we may be making the same mistakes and catch them early, while still not allowing stupid shit to get though. This creates a natural tension. For example, vaccines & cigarettes:

Should we look into the safety of Vaccines? Of course! But it only takes a little fear mongering and one [crazy ex-physician](https://en.wikipedia.org/wiki/Andrew_Wakefield) with a known [conflict of interest](https://en.wikipedia.org/wiki/Lancet_MMR_autism_fraud#Conflict_of_interest) writing a paper linking vaccines to autism to result in countless extra deaths. 

Should we look into the safety of cigarettes? Yeah, no shit. However, our over hesitancy to declare them cancerous doubtlessly lead to tons more cancer world wide. Why? Because of ton of academic papers, funded by the cigarette companies, that basically boiled down to "Yeah, people are getting cancer more, but maybe that's plastic use, or this, or that - you don't *know* that it's cigarettes causing it", and then, when the link became undeniable, they just spun it as "Of course, we've always told you it can cause cancer, but you knew that going in!"

{{< smalltext >}}Of note, I could also really say Nazis fall into this boat too, as a failing to identify their ideas as evil and convince enough people of that to stop it lead to WWⅡ; however, I think that is to reductive of history and of the efforts of people who did actually try to stop it from the start. Also I don't want to add fuel to the fire of [Godwin's Law](https://en.wikipedia.org/wiki/Godwin's_law){{< /smalltext >}}

In both of these, the cost of failing to declare the studies as bullshit from the start resulted in deaths. While one was an over-abundance of caution, the other was a lack of. Both should be appreciated as equally dangerous.

Meanwhile, failing to let new ideas surface because they sound crazy can cause similar issues. Unfortunately, these examples are a lot harder to identify. There's the obvious poster child examples, like the light bulb that supposedly got  significant push back for never having the possibility of being commercially viable, or Airplanes and the story of the Wright Brothers. The real question is what inventions did we lose or get a hundred years late because the ideas were ridiculed?

We can never fully making mistakes. Some bad ideas will get though, and propagate enough to become diseased. Some good ideas will be squashed early. We should try our best though. This means encouraging people with new ideas to test them out while also helping people recognize what may make an idea dangerous - while avoiding falling into patterns that lead to not questioning our own beliefs and without going off the deep end and questioning everything that keeps society moving.

Balance skepticism with openness.

---

## Religion?

I very intentionally didn't bring religion into any of this, because I am aware of my own biases. That said, I think some may find the series [Philosophical Failures of Christian Apologetics (AntiCitizenX, YouTube)](https://www.youtube.com/watch?v=lroKN5gdm08&list=PL3IOkNR8_9gpQa5teO1xQANB-3MiY17uk) interesting. I think it makes some interesting points and may even be interesting for readers that are currently on the fence about religion. I want to be clear, I don't see *any* religion as a "diseased idea" as I put it above; however, I do see many of the things that many religions preach as such. I think having belief in a higher power is fine, especially since mortality is scary and it can help. What I don't think is fine is claiming that higher power justifies ignoring scientific studies or hating a group of people because of a bullshit excuse provided by (or grossly grafted onto) that belief system. Your religion (or lack of) doesn't give you a right to be a dick or be ignorant.

---

## A small exception

I said the best thing you can do is to remove the platform, right? Well, there's another, risky, option: Let them look like absolute idiots on your platform without being directly malicious. Let them trip over themselves. This requires a lot of skill, a particularly poorly informed but confident individual, and an unsympathetic character. There's a lot of reasons you shouldn't try to do this, but when done well it can be a work of art. That said, this same though may well be why Trump won the 2016 election, as he was shown on every news station but not taken seriously- so proceed with caution.

<blockquote class="twitter-tweet" data-dnt="true"><p lang="en" dir="ltr">There&#39;s power in understanding a position you oppose better than people who support it. You can avoid looking foolish like this. <a href="https://t.co/jTzX2lhQs7">https://t.co/jTzX2lhQs7</a></p>&mdash; Kye Fox (@KyeFox) <a href="https://twitter.com/KyeFox/status/1455519411503251463?ref_src=twsrc%5Etfw">November 2, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<iframe width="100%" height="500" src="https://www.youtube.com/embed/NzDhm808oU4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

